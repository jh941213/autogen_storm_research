"""AutoGen STORM Research Assistant Workflow

ì´ ëª¨ë“ˆì€ AutoGenì˜ GraphFlowë¥¼ ì‚¬ìš©í•˜ì—¬ STORM ì—°êµ¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
ìë™ ëª¨ë“œì™€ ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œë¥¼ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.
"""

import json
import asyncio
import uuid
from typing import List, Dict, Any, Optional
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination
from autogen_agentchat.agents import AssistantAgent
from autogen_core.models import ChatCompletionClient

from .agents import (
    create_analyst_generator_agent,
    create_interviewer_agent,
    create_expert_agent,
    create_section_writer_agent,
    create_report_writer_agent,
    create_intro_writer_agent,
    create_conclusion_writer_agent,
    create_feedback_aware_interviewer,
    create_feedback_aware_report_writer,
    create_feedback_aware_intro_writer,
    create_feedback_aware_conclusion_writer
)
from .models import Analyst, ResearchTask, ResearchResult, InterviewResult, Perspectives
from .config import StormConfig, ModelConfig
from .tracing import get_tracing_manager


def safe_input(prompt: str, fallback_prompt: str = None) -> str:
    """Safely handle input with encoding issues"""
    try:
        return input(prompt).strip()
    except UnicodeDecodeError:
        print("ì…ë ¥ ì¸ì½”ë”© ì˜¤ë¥˜. ìˆ«ìë‚˜ ì˜ë¬¸ë§Œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        fallback = fallback_prompt or prompt.replace("í•œêµ­ì–´", "Korean").replace("ì„ íƒ", "Choice")
        return input(fallback).strip()


class StormWorkflow:
    """STORM ì—°êµ¬ ì›Œí¬í”Œë¡œìš° í´ë˜ìŠ¤ - ìë™ ëª¨ë“œì™€ ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ í†µí•©"""
    
    def __init__(self, config: StormConfig, interactive_mode: bool = False):
        """ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
        
        Args:
            config: STORM ì„¤ì •
            interactive_mode: ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ í™œì„±í™” ì—¬ë¶€
        """
        self.config = config
        self.interactive_mode = interactive_mode
        self.tracing_manager = get_tracing_manager()
        
        # ê¸°ë³¸ ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        model_config = config.model_config.to_autogen_config()
        self.model_client = ChatCompletionClient.load_component(model_config)
        
        # ì—ì´ì „íŠ¸ë³„ ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        self.expert_model_client = self._create_model_client(config.expert_model_config)
        self.writer_model_client = self._create_model_client(config.writer_model_config)
        self.analyst_model_client = self._create_model_client(config.analyst_model_config)
        self.interviewer_model_client = self._create_model_client(config.interviewer_model_config)
        
        # ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œë¥¼ ìœ„í•œ ìƒíƒœ
        if self.interactive_mode:
            self.current_analysts: List[Analyst] = []
            self.current_interviews: List[InterviewResult] = []
            self.current_report_parts: Dict[str, str] = {}
            self.current_task: Optional[ResearchTask] = None
            self.report_versions: List[Dict[str, str]] = []
    
    def _create_model_client(self, model_config: Optional[ModelConfig]):
        """ëª¨ë¸ ì„¤ì •ì—ì„œ í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ì—†ìœ¼ë©´ ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©)"""
        if model_config is None:
            return self.model_client
        
        config_dict = model_config.to_autogen_config()
        return ChatCompletionClient.load_component(config_dict)
        
    async def run_research(self, task: ResearchTask) -> ResearchResult:
        """ì—°êµ¬ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤
        
        Args:
            task: ì—°êµ¬ ì‘ì—…
            
        Returns:
            ì—°êµ¬ ê²°ê³¼
        """
        if self.interactive_mode:
            return await self._run_interactive_research(task)
        else:
            return await self._run_automatic_research(task)
    
    async def _run_automatic_research(self, task: ResearchTask) -> ResearchResult:
        """ìë™ ëª¨ë“œë¡œ ì—°êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤"""
        # Langfuse ì¶”ì  ì‹œì‘
        task_id = str(uuid.uuid4())
        
        with self.tracing_manager.trace_research(topic=task.topic, task_id=task_id) as trace:
            try:
                print(f"ğŸ”¬ ì—°êµ¬ ì‹œì‘: {task.topic}")
                if trace:
                    trace_url = self.tracing_manager.get_trace_url()
                    if trace_url:
                        print(f"ğŸ” Langfuse ì¶”ì  ì‹œì‘ - Trace URL: {trace_url}")
                
                # 1ë‹¨ê³„: ë¶„ì„ê°€ ìƒì„±
                print("ğŸ‘¥ ë¶„ì„ê°€ ìƒì„± ì¤‘...")
                analysts = await self._generate_analysts_with_diverse_tools(task)
                print(f"âœ… {len(analysts)}ëª…ì˜ ë¶„ì„ê°€ ìƒì„± ì™„ë£Œ")
                
                # ë¶„ì„ê°€ ìƒì„± ì´ë²¤íŠ¸ ë¡œê¹…
                self.tracing_manager.log_event(
                    "analysts_created",
                    {
                        "count": len(analysts),
                        "analysts": [{"name": a.name, "role": a.role} for a in analysts]
                    }
                )
                
                # 2ë‹¨ê³„: ë³‘ë ¬ ì¸í„°ë·° ì§„í–‰
                print("ğŸ¤ ì¸í„°ë·° ì§„í–‰ ì¤‘...")
                interviews = await self._conduct_interviews(analysts, task)
                print(f"âœ… {len(interviews)}ê°œì˜ ì¸í„°ë·° ì™„ë£Œ")
                
                # ì¸í„°ë·° ì™„ë£Œ ì´ë²¤íŠ¸ ë¡œê¹…
                self.tracing_manager.log_event(
                    "interviews_completed",
                    {"count": len(interviews)}
                )
                
                # 3ë‹¨ê³„: ë³´ê³ ì„œ ì‘ì„±
                print("ğŸ“ ë³´ê³ ì„œ ì‘ì„± ì¤‘...")
                report_parts = await self._write_report(task.topic, interviews)
                print("âœ… ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œ")
                
                # ìµœì¢… ê²°ê³¼ ì¡°í•©
                final_report = self._assemble_final_report(report_parts)
                
                # ë³´ê³ ì„œ ìƒì„± ë¡œê¹…
                self.tracing_manager.log_generation(
                    "final_report",
                    input_data={"topic": task.topic, "analyst_count": len(analysts)},
                    output_data={"length": len(final_report), "word_count": len(final_report.split())}
                )
                
                result = ResearchResult(
                    topic=task.topic,
                    analysts=analysts,
                    interviews=interviews,
                    introduction=report_parts["introduction"],
                    main_content=report_parts["main_content"],
                    conclusion=report_parts["conclusion"],
                    final_report=final_report
                )
                
                # ì„±ê³µ ì´ë²¤íŠ¸ ë¡œê¹…
                self.tracing_manager.log_event(
                    "research_completed",
                    {
                        "analyst_count": len(analysts),
                        "interview_count": len(interviews),
                        "report_length": len(final_report),
                        "word_count": len(final_report.split())
                    }
                )
                
                return result
            
            except Exception as e:
                print(f"âŒ ì—°êµ¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                
                # ì—ëŸ¬ ì´ë²¤íŠ¸ ë¡œê¹…
                self.tracing_manager.log_event(
                    "research_error",
                    {"error": str(e), "error_type": type(e).__name__},
                    level="ERROR"
                )
                
                raise
    
    async def _run_interactive_research(self, task: ResearchTask) -> ResearchResult:
        """ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œë¡œ ì—°êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤"""
        print(f"\nğŸš€ ì¸í„°ë™í‹°ë¸Œ STORM ì—°êµ¬ ì‹œì‘: {task.topic}")
        print("="*60)
        
        # 1ë‹¨ê³„: ë¶„ì„ê°€ ìˆ˜ ì„ íƒ (íœ´ë¨¼ í”¼ë“œë°±)
        final_analyst_count = self._get_analyst_count_from_user(task.max_analysts)
        task.max_analysts = final_analyst_count
        
        print(f"\nğŸ‘¥ {final_analyst_count}ëª…ì˜ ë¶„ì„ê°€ë¡œ ì—°êµ¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...")
        
        # 2ë‹¨ê³„: ìë™ ì—°êµ¬ ì§„í–‰ (ë‹¤ì–‘í•œ íˆ´ í™œìš© ë¶„ì„ê°€ ìƒì„± â†’ ì¸í„°ë·° â†’ ë³´ê³ ì„œ ì‘ì„±)
        print("\nğŸ” ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ íˆ´ì„ í™œìš©í•˜ëŠ” ë¶„ì„ê°€ ìƒì„± ì¤‘...")
        analysts = await self._generate_analysts_with_diverse_tools(task)
        self.current_analysts = analysts  # ìƒíƒœ ì €ì¥
        
        print(f"\nğŸ¤ {len(analysts)}ëª…ì˜ ë¶„ì„ê°€ì™€ ì¸í„°ë·° ì§„í–‰ ì¤‘...")
        interviews = await self._conduct_interviews(analysts, task)
        self.current_interviews = interviews  # ìƒíƒœ ì €ì¥
        
        print(f"\nğŸ“ {len(interviews)}ê°œì˜ ì¸í„°ë·°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œ ì‘ì„± ì¤‘...")
        report_parts = await self._write_report(task.topic, interviews)
        
        # 3ë‹¨ê³„: ìµœì¢… ë³´ê³ ì„œ ìŠ¹ì¸ (íœ´ë¨¼ í”¼ë“œë°±)
        final_report_parts = await self._get_final_report_approval(task.topic, report_parts)
        
        # ìµœì¢… ê²°ê³¼ ì¡°í•©
        final_report = self._assemble_final_report(final_report_parts)
        
        return ResearchResult(
            topic=task.topic,
            analysts=analysts,
            interviews=interviews,
            introduction=final_report_parts["introduction"],
            main_content=final_report_parts["main_content"],
            conclusion=final_report_parts["conclusion"],
            final_report=final_report
        )
    
    def _get_analyst_count_from_user(self, default_count: int) -> int:
        """ì‚¬ìš©ìë¡œë¶€í„° ë¶„ì„ê°€ ìˆ˜ë¥¼ ì…ë ¥ë°›ìŠµë‹ˆë‹¤"""
        
        print(f"\nğŸ‘¥ ë¶„ì„ê°€ ìˆ˜ ì„ íƒ")
        print("="*40)
        print(f"ê¸°ë³¸ ì„¤ì •: {default_count}ëª…ì˜ ë¶„ì„ê°€")
        print("ë” ë§ì€ ë¶„ì„ê°€ëŠ” ë” ë‹¤ì–‘í•œ ê´€ì ì„ ì œê³µí•˜ì§€ë§Œ ì‹œê°„ì´ ë” ê±¸ë¦½ë‹ˆë‹¤.")
        
        while True:
            try:
                user_input = safe_input(
                    f"\nì›í•˜ëŠ” ë¶„ì„ê°€ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-10, ê¸°ë³¸ê°’: {default_count}): ",
                    f"Enter number of analysts (1-10, default: {default_count}): "
                )
                
                if not user_input:  # ì—”í„°ë§Œ ëˆ„ë¥¸ ê²½ìš°
                    return default_count
                
                count = int(user_input)
                if 1 <= count <= 10:
                    return count
                else:
                    print("âŒ 1-10 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    
            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    async def _get_final_report_approval(self, topic: str, report_parts: Dict[str, str]) -> Dict[str, str]:
        """ìµœì¢… ë³´ê³ ì„œ ìŠ¹ì¸ì„ ë°›ìŠµë‹ˆë‹¤"""
        
        # ì²« ë²ˆì§¸ ë³´ê³ ì„œ ë²„ì „ ì €ì¥
        self.report_versions.append(report_parts.copy())
        self.current_report_parts = report_parts.copy()  # í˜„ì¬ ë³´ê³ ì„œ ì €ì¥
        
        print(f"\nğŸ“‹ ìµœì¢… ë³´ê³ ì„œ ê²€í†  (ë²„ì „ {len(self.report_versions)})")
        print("="*60)
        
        # ì „ì²´ ë³´ê³ ì„œ ê¸¸ì´ ê³„ì‚° (ë¹ˆ ë¬¸ìì—´ ê³ ë ¤)
        total_length = len((report_parts.get('introduction', '') or '') + 
                          (report_parts.get('main_content', '') or '') + 
                          (report_parts.get('conclusion', '') or ''))
        
        # ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸° ìƒì„±
        preview = f"""
ğŸ“– **ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸° (ë²„ì „ {len(self.report_versions)})**

**ì„œë¡  (ì²˜ìŒ 200ì):**
{(report_parts.get('introduction', '') or 'ì„œë¡  ë‚´ìš©ì´ ë¹ˆ ê°’ì…ë‹ˆë‹¤.')[:200]}...

**ë³¸ë¬¸ (ì²˜ìŒ 300ì):**
{(report_parts.get('main_content', '') or 'ë³¸ë¬¸ ë‚´ìš©ì´ ë¹ˆ ê°’ì…ë‹ˆë‹¤.')[:300]}...

**ê²°ë¡  (ì²˜ìŒ 200ì):**
{(report_parts.get('conclusion', '') or 'ê²°ë¡  ë‚´ìš©ì´ ë¹ˆ ê°’ì…ë‹ˆë‹¤.')[:200]}...

ì „ì²´ ë³´ê³ ì„œ ê¸¸ì´: ì•½ {total_length}ì
"""
        
        print(preview)
        
        while True:
            menu_options = [
                "1. âœ… ìŠ¹ì¸ - ì´ ë³´ê³ ì„œë¡œ ì™„ë£Œ",
                "2. ğŸ”„ ì¬ì‘ì„± - ë³´ê³ ì„œë¥¼ ë‹¤ì‹œ ì‘ì„±",
                "3. ğŸ“„ ì „ì²´ë³´ê¸° - ì „ì²´ ë³´ê³ ì„œ ë‚´ìš© í™•ì¸"
            ]
            
            # ì´ì „ ë²„ì „ì´ ìˆëŠ” ê²½ìš° ë¹„êµ ì˜µì…˜ ì¶”ê°€
            if len(self.report_versions) > 1:
                menu_options.append("4. ğŸ” ì´ì „ ë²„ì „ê³¼ ë¹„êµ")
            
            print(f"\në‹¤ìŒ ì¤‘ ì„ íƒí•´ì£¼ì„¸ìš”:")
            for option in menu_options:
                print(option)
            
            choice = safe_input(
                f"\nì„ íƒ (1-{len(menu_options)}): ",
                f"Choice (1-{len(menu_options)}): "
            )
            
            if choice == "1":
                print("\nâœ… ë³´ê³ ì„œê°€ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
                print(f"ğŸ’¾ ì´ {len(self.report_versions)}ê°œì˜ ë²„ì „ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return report_parts
                
            elif choice == "2":
                print("\nğŸ”„ ë³´ê³ ì„œ ì¬ì‘ì„± ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
                print("1. ğŸ”„ ì™„ì „ ì¬ì—°êµ¬ (ìƒˆë¡œìš´ ì¸í„°ë·°ë¶€í„° ë‹¤ì‹œ)")
                print("2. âœï¸ ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜ ì¬ì‘ì„±")
                
                rewrite_choice = safe_input(
                    "\nì¬ì‘ì„± ë°©ì‹ ì„ íƒ (1-2): ",
                    "Choice (1-2): "
                )
                
                if rewrite_choice == "1":
                    print("\nğŸ”„ ì™„ì „íˆ ìƒˆë¡œìš´ ì—°êµ¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
                    print("ğŸ’¡ ë‹¤ì–‘í•œ íˆ´ì„ í™œìš©í•˜ëŠ” ìƒˆë¡œìš´ ë¶„ì„ê°€ë“¤ë¡œ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì¬ì‹¤í–‰í•©ë‹ˆë‹¤.")
                    # ìƒˆë¡œìš´ ì „ì²´ ì—°êµ¬ ì§„í–‰
                    task_copy = ResearchTask(
                        topic=topic,
                        max_analysts=len(self.current_analysts),
                        max_interview_turns=3,
                        parallel_interviews=True
                    )
                    # ì „ì²´ ì›Œí¬í”Œë¡œìš° ì¬ì‹¤í–‰
                    research_result = await self._run_automatic_research(task_copy)
                    new_report_parts = {
                        "main_content": research_result.main_content,
                        "introduction": research_result.introduction,
                        "conclusion": research_result.conclusion
                    }
                    # ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸
                    self.current_analysts = research_result.analysts
                    self.current_interviews = research_result.interviews
                    
                elif rewrite_choice == "2":
                    print("\nâœï¸ ì–´ë–¤ ë¶€ë¶„ì„ ê°œì„ í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
                    feedback = safe_input(
                        "ê°œì„  ìš”ì²­ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”: ",
                        "Enter improvement request: "
                    )
                    if feedback:
                        print(f"\nğŸ’¡ í”¼ë“œë°± ë°˜ì˜: {feedback}")
                        print("ğŸ”„ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ìƒˆë¡œìš´ ì¸í„°ë·°ë¶€í„° ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤...")
                        print("âš ï¸ ì™„ì „íˆ ìƒˆë¡œìš´ ê´€ì ê³¼ ë‚´ìš©ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                        new_report_parts = await self._rewrite_with_feedback(topic, feedback)
                    else:
                        print("í”¼ë“œë°±ì´ ì—†ì–´ ê¸°ë³¸ ì¬ì‘ì„±ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                        new_report_parts = await self._write_report(topic, self.current_interviews)
                else:
                    print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ê¸°ë³¸ ì¬ì‘ì„±ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                    new_report_parts = await self._write_report(topic, self.current_interviews)
                
                # ìƒˆ ë²„ì „ì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                self.report_versions.append(new_report_parts.copy())
                self.current_report_parts = new_report_parts.copy()  # í˜„ì¬ ë³´ê³ ì„œ ì—…ë°ì´íŠ¸
                
                # ì¬ì‘ì„±ëœ ë³´ê³ ì„œë¡œ ë‹¤ì‹œ ê²€í†  (ë£¨í”„ ê³„ì†)
                print(f"\nâœ¨ ë³´ê³ ì„œê°€ ì¬ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! (ë²„ì „ {len(self.report_versions)})")
                report_parts = new_report_parts
                continue  # while ë£¨í”„ ê³„ì†í•´ì„œ ë‹¤ì‹œ ê²€í† 
                
            elif choice == "3":
                self._show_full_report(report_parts)
                
            elif choice == "4" and len(self.report_versions) > 1:
                self._compare_report_versions()
                
            else:
                print(f"âŒ 1-{len(menu_options)}ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    def _show_full_report(self, report_parts: Dict[str, str]):
        """ì „ì²´ ë³´ê³ ì„œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤"""
        
        print("\n" + "="*80)
        print("ğŸ“„ ì „ì²´ ë³´ê³ ì„œ")
        print("="*80)
        
        print("\nğŸ”¸ ì„œë¡ ")
        print("-" * 40)
        print(report_parts['introduction'])
        
        print("\nğŸ”¸ ë³¸ë¬¸")
        print("-" * 40)
        print(report_parts['main_content'])
        
        print("\nğŸ”¸ ê²°ë¡ ")
        print("-" * 40)
        print(report_parts['conclusion'])
        
        print("\n" + "="*80)
        
        safe_input("\nê³„ì†í•˜ë ¤ë©´ ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”...", "Press Enter to continue...")  # ì‚¬ìš©ìê°€ ì½ì„ ì‹œê°„ ì œê³µ
    
    def _compare_report_versions(self):
        """ë³´ê³ ì„œ ë²„ì „ë“¤ì„ ë¹„êµí•©ë‹ˆë‹¤"""
        
        print("\n" + "="*80)
        print("ğŸ” ë³´ê³ ì„œ ë²„ì „ ë¹„êµ")
        print("="*80)
        
        print(f"\nì´ {len(self.report_versions)}ê°œì˜ ë²„ì „ì´ ìˆìŠµë‹ˆë‹¤:")
        
        # ê° ë²„ì „ì˜ ìš”ì•½ ì •ë³´ í‘œì‹œ
        for i, version in enumerate(self.report_versions, 1):
            intro_preview = version['introduction'][:100] + "..." if len(version['introduction']) > 100 else version['introduction']
            total_length = len(version['introduction'] + version['main_content'] + version['conclusion'])
            
            print(f"\nğŸ“„ ë²„ì „ {i}:")
            print(f"   ì„œë¡  ë¯¸ë¦¬ë³´ê¸°: {intro_preview}")
            print(f"   ì „ì²´ ê¸¸ì´: {total_length}ì")
        
        # ë¹„êµí•  ë²„ì „ ì„ íƒ
        while True:
            try:
                version_num = safe_input(
                    f"\nì–´ë–¤ ë²„ì „ì„ ìì„¸íˆ ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (1-{len(self.report_versions)}, 0=ì·¨ì†Œ): ",
                    f"Which version would you like to see? (1-{len(self.report_versions)}, 0=cancel): "
                )
                
                if version_num == "0":
                    print("ë¹„êµë¥¼ ì·¨ì†Œí•©ë‹ˆë‹¤.")
                    break
                
                version_idx = int(version_num) - 1
                if 0 <= version_idx < len(self.report_versions):
                    selected_version = self.report_versions[version_idx]
                    
                    print(f"\nğŸ“– ë²„ì „ {version_num} ì „ì²´ ë‚´ìš©:")
                    print("-" * 60)
                    
                    print(f"\nğŸ”¸ ì„œë¡ ")
                    print("-" * 30)
                    print(selected_version['introduction'])
                    
                    print(f"\nğŸ”¸ ë³¸ë¬¸")
                    print("-" * 30)
                    print(selected_version['main_content'])
                    
                    print(f"\nğŸ”¸ ê²°ë¡ ")
                    print("-" * 30)
                    print(selected_version['conclusion'])
                    
                    print("-" * 60)
                    
                    # ê³„ì† ë‹¤ë¥¸ ë²„ì „ì„ ë³¼ì§€ ë¬¼ì–´ë³´ê¸°
                    continue_choice = safe_input(
                        "\në‹¤ë¥¸ ë²„ì „ì„ ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ",
                        "View another version? (y/n): "
                    ).lower()
                    if continue_choice != 'y':
                        break
                else:
                    print(f"âŒ 1-{len(self.report_versions)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    
            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        print("\n" + "="*80)
        safe_input("\nê³„ì†í•˜ë ¤ë©´ ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”...", "Press Enter to continue...")
    
    async def _rewrite_with_feedback(self, topic: str, feedback: str) -> Dict[str, str]:
        """ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ê¸°ì¡´ ë¶„ì„ê°€ + ì¶”ê°€ ë¶„ì„ê°€ë¡œ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì¬ì‹¤í–‰í•©ë‹ˆë‹¤"""
        
        print("ğŸ”„ í”¼ë“œë°±ì„ ë°˜ì˜í•œ ì¶”ê°€ ë¶„ì„ê°€ ìƒì„± ì¤‘...")
        
        # í”¼ë“œë°±ì„ ë°˜ì˜í•œ ì¶”ê°€ ë¶„ì„ê°€ 1ëª… ìƒì„±
        task_with_feedback = ResearchTask(
            topic=topic,
            max_analysts=1,  # ì¶”ê°€ ë¶„ì„ê°€ 1ëª…ë§Œ
            max_interview_turns=3,
            parallel_interviews=True,
            user_feedback=feedback
        )
        
        # ì¶”ê°€ ë¶„ì„ê°€ ìƒì„±
        additional_analyst = await self._generate_additional_analyst_with_feedback(
            task_with_feedback, 
            feedback,
            self.current_analysts
        )
        
        print(f"ğŸ¤ ì¶”ê°€ ë¶„ì„ê°€ '{additional_analyst.name}'ì™€ í•¨ê»˜ í”¼ë“œë°± ì¤‘ì‹¬ ì›Œí¬í”Œë¡œìš° ì¬ì‹¤í–‰ ì¤‘...")
        print(f"ğŸ‘¥ ì´ {len(self.current_analysts) + 1}ëª…ì˜ ë¶„ì„ê°€ë¡œ í”¼ë“œë°± ì¤‘ì‹¬ ì—°êµ¬ ì§„í–‰")
        
        # ê¸°ì¡´ ë¶„ì„ê°€ë“¤ + ì¶”ê°€ ë¶„ì„ê°€ë¡œ ì „ì²´ ì›Œí¬í”Œë¡œìš° ì¬ì‹¤í–‰
        all_analysts = self.current_analysts + [additional_analyst]
        updated_task = ResearchTask(
            topic=topic,
            max_analysts=len(all_analysts),
            max_interview_turns=3,
            parallel_interviews=True,
            user_feedback=feedback  # í”¼ë“œë°± ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        )
        
        # í”¼ë“œë°± ì»¨í…ìŠ¤íŠ¸ê°€ ê°•í™”ëœ ì¸í„°ë·° ì§„í–‰
        print(f"\nğŸ¤ {len(all_analysts)}ëª…ì˜ ë¶„ì„ê°€ì™€ í”¼ë“œë°± ì¤‘ì‹¬ ì¸í„°ë·° ì§„í–‰ ì¤‘...")
        interviews = await self._conduct_feedback_aware_interviews(all_analysts, updated_task, feedback)
        print(f"âœ… {len(interviews)}ê°œì˜ í”¼ë“œë°± ì¤‘ì‹¬ ì¸í„°ë·° ì™„ë£Œ")
        
        # í”¼ë“œë°±ì´ ë°˜ì˜ëœ ë³´ê³ ì„œ ì‘ì„±
        print("\nğŸ“ í”¼ë“œë°±ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë³´ê³ ì„œ ì‘ì„± ì¤‘...")
        report_parts = await self._write_feedback_aware_report(topic, interviews, feedback)
        print("âœ… í”¼ë“œë°± ì¤‘ì‹¬ ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œ")
        
        # ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.current_analysts = all_analysts
        self.current_interviews = interviews
        
        return report_parts
    
    async def _generate_analysts(self, task: ResearchTask) -> List[Analyst]:
        """ë¶„ì„ê°€ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤"""
        
        generator_agent = create_analyst_generator_agent(self.analyst_model_client)
        
        # ë¶„ì„ê°€ ìƒì„± ìš”ì²­
        prompt = f"""ë‹¤ìŒ ì—°êµ¬ ì£¼ì œì— ëŒ€í•´ {task.max_analysts}ëª…ì˜ ì „ë¬¸ ë¶„ì„ê°€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

        ì£¼ì œ: {task.topic}

        ê° ë¶„ì„ê°€ëŠ” ì„œë¡œ ë‹¤ë¥¸ ê´€ì ê³¼ ì „ë¬¸ì„±ì„ ê°€ì ¸ì•¼ í•˜ë©°, ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:

        {{
            "analysts": [
                {{
                    "name": "ë¶„ì„ê°€ ì´ë¦„",
                    "role": "ì—­í• ",
                    "affiliation": "ì†Œì† ê¸°ê´€",
                    "description": "ê´€ì‹¬ì‚¬ì™€ ì „ë¬¸ì„±ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…"
                }}
            ]
        }}"""
        
        # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰
        team = RoundRobinGroupChat(
            [generator_agent],
            termination_condition=MaxMessageTermination(max_messages=2)
        )
        
        result = await team.run(task=prompt)
        response_text = result.messages[-1].content
        
        # JSON íŒŒì‹±
        try:
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            json_str = response_text[start_idx:end_idx]
            
            data = json.loads(json_str)
            perspectives = Perspectives(**data)
            return perspectives.analysts
        except Exception as e:
            print(f"ë¶„ì„ê°€ íŒŒì‹± ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ ë¶„ì„ê°€ ë°˜í™˜
            return [
                Analyst(
                    name="ì¼ë°˜ ì—°êµ¬ì",
                    role="ì—°êµ¬ ë¶„ì„ê°€",
                    affiliation="ì—°êµ¬ ê¸°ê´€",
                    description=f"{task.topic}ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì—°êµ¬ì™€ ë¶„ì„ì„ ë‹´ë‹¹"
                )
            ]
    
    async def _generate_analysts_with_diverse_tools(self, task: ResearchTask) -> List[Analyst]:
        """ë‹¤ì–‘í•œ íˆ´ê³¼ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í™œìš©í•  ìˆ˜ ìˆëŠ” ë¶„ì„ê°€ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤"""
        
        generator_agent = create_analyst_generator_agent(self.analyst_model_client)
        
        # ë‹¤ì–‘í•œ íˆ´ê³¼ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ê³ ë ¤í•œ ë¶„ì„ê°€ ìƒì„± í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¤ìŒ ì—°êµ¬ ì£¼ì œì— ëŒ€í•´ {task.max_analysts}ëª…ì˜ ë‹¤ì–‘í•œ ì „ë¬¸ ë¶„ì„ê°€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

        ì£¼ì œ: {task.topic}

        ì¤‘ìš”: ê° ë¶„ì„ê°€ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê²€ìƒ‰ ë„êµ¬ë“¤ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ê²€ìƒ‰ ë„êµ¬:
        - web_search: ì›¹ì—ì„œ ìµœì‹  ì •ë³´ì™€ ì¼ë°˜ì ì¸ ì£¼ì œ ê²€ìƒ‰ (Tavily API)
        - duckduckgo_search: í”„ë¼ì´ë²„ì‹œ ì¤‘ì‹œ ê²€ìƒ‰ê³¼ ì¦‰ì„ ë‹µë³€
        - naver_news_search: í•œêµ­ ê´€ë ¨ ë‰´ìŠ¤ì™€ ìµœì‹  ì´ìŠˆ ê²€ìƒ‰
        - wikipedia_search: ë°±ê³¼ì‚¬ì „ ì •ë³´, ê¸°ë³¸ ê°œë…, ì •ì˜, ì—­ì‚¬ì  ë°°ê²½
        - arxiv_search: ê³¼í•™ì , ê¸°ìˆ ì  ì£¼ì œì˜ í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰
        
        ë°ì´í„° ì†ŒìŠ¤ í™œìš© ì˜ˆì‹œ:
        - í•™ìˆ  ì—°êµ¬: ArXiv ë…¼ë¬¸ + Wikipedia ë°°ê²½ì§€ì‹ + ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ìµœì‹  ë™í–¥
        - ì‹œì¥ ë¶„ì„: ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì‚°ì—… ë™í–¥ + ë‰´ìŠ¤ ê²€ìƒ‰ìœ¼ë¡œ ìµœì‹  ì´ìŠˆ
        - ê¸°ìˆ  ë™í–¥: ArXiv ìµœì‹  ë…¼ë¬¸ + ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì‹¤ì œ ì ìš© ì‚¬ë¡€
        - ì‚¬íšŒ ì´ìŠˆ: ë‰´ìŠ¤ ê²€ìƒ‰ + Wikipedia ë°°ê²½ + DuckDuckGoë¡œ ë‹¤ì–‘í•œ ê´€ì 
        - ì—­ì‚¬/ë¬¸í™”: Wikipedia ê¸°ë³¸ ì •ë³´ + ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ìƒì„¸ ìë£Œ
        
        ê° ë¶„ì„ê°€ëŠ” ì„œë¡œ ë‹¤ë¥¸ ê´€ì ê³¼ ì „ë¬¸ì„±ì„ ê°€ì ¸ì•¼ í•˜ë©°, ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:

        {{
            "analysts": [
                {{
                    "name": "ë¶„ì„ê°€ ì´ë¦„",
                    "role": "ì—­í• ",
                    "affiliation": "ì†Œì† ê¸°ê´€",
                    "description": "ê´€ì‹¬ì‚¬, ì „ë¬¸ì„±, ê·¸ë¦¬ê³  ì–´ë–¤ ê²€ìƒ‰ ë„êµ¬ë“¤ì„ ì£¼ë¡œ í™œìš©í• ì§€ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì„¤ëª… (ì˜ˆ: 'ArXivì™€ ì›¹ ê²€ìƒ‰ì„ í™œìš©í•œ ìµœì‹  AI ê¸°ìˆ  ë™í–¥ ë¶„ì„')"
                }}
            ]
        }}"""
        
        # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰
        team = RoundRobinGroupChat(
            [generator_agent],
            termination_condition=MaxMessageTermination(max_messages=2)
        )
        
        result = await team.run(task=prompt)
        response_text = result.messages[-1].content
        
        # JSON íŒŒì‹±
        try:
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            json_str = response_text[start_idx:end_idx]
            
            data = json.loads(json_str)
            perspectives = Perspectives(**data)
            return perspectives.analysts
        except Exception as e:
            print(f"ë‹¤ì–‘í•œ íˆ´ ë¶„ì„ê°€ íŒŒì‹± ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ ë¶„ì„ê°€ ë°˜í™˜
            return [
                Analyst(
                    name="ë‹¤ì–‘í•œ ë°ì´í„° ì „ë¬¸ê°€",
                    role="ë°ì´í„° ë§ˆì´ë‹ ì „ë¬¸ê°€",
                    affiliation="ì—°êµ¬ ê¸°ê´€",
                    description=f"{task.topic}ì— ëŒ€í•œ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ ë¶„ì„ íˆ´ì„ í™œìš©í•œ ì—°êµ¬ë¥¼ ë‹´ë‹¹"
                )
            ]
    
    async def _generate_additional_analyst_with_feedback(self, task: ResearchTask, feedback: str, existing_analysts: List[Analyst]) -> Analyst:
        """í”¼ë“œë°±ì„ ë°˜ì˜í•œ ì¶”ê°€ ë¶„ì„ê°€ 1ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤"""
        
        analyst_generator = create_analyst_generator_agent(self.analyst_model_client)
        
        # ê¸°ì¡´ ë¶„ì„ê°€ ì •ë³´ êµ¬ì„±
        existing_context = "**ê¸°ì¡´ ë¶„ì„ê°€ë“¤:**\n"
        for analyst in existing_analysts:
            existing_context += f"- {analyst.name} ({analyst.role}): {analyst.description}\n"
        
        # í”¼ë“œë°±ì„ ë°˜ì˜í•œ ì¶”ê°€ ë¶„ì„ê°€ ìƒì„± í”„ë¡¬í”„íŠ¸
        analyst_prompt = f"""
        ì£¼ì œ: {task.topic}
        ì‚¬ìš©ì í”¼ë“œë°±: {feedback}
        
        {existing_context}
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ê²€ìƒ‰ ë„êµ¬:
        - web_search: ì›¹ì—ì„œ ìµœì‹  ì •ë³´ì™€ ì¼ë°˜ì ì¸ ì£¼ì œ ê²€ìƒ‰
        - duckduckgo_search: í”„ë¼ì´ë²„ì‹œ ì¤‘ì‹œ ê²€ìƒ‰ê³¼ ì¦‰ì„ ë‹µë³€
        - naver_news_search: í•œêµ­ ê´€ë ¨ ë‰´ìŠ¤ì™€ ìµœì‹  ì´ìŠˆ ê²€ìƒ‰
        - wikipedia_search: ë°±ê³¼ì‚¬ì „ ì •ë³´, ê¸°ë³¸ ê°œë…, ì •ì˜, ì—­ì‚¬ì  ë°°ê²½
        - arxiv_search: ê³¼í•™ì , ê¸°ìˆ ì  ì£¼ì œì˜ í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰
        
        ìœ„ í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬, ê¸°ì¡´ ë¶„ì„ê°€ë“¤ì´ ë‹¤ë£¨ì§€ ëª»í•œ ê´€ì ì„ ë³´ì™„í•  ìˆ˜ ìˆëŠ” 
        ì¶”ê°€ ë¶„ì„ê°€ 1ëª…ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
        
        ìš”êµ¬ì‚¬í•­:
        1. í”¼ë“œë°±ì—ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì  ìš”êµ¬ì‚¬í•­ì— ì§ì ‘ ëŒ€ì‘
        2. ê¸°ì¡´ ë¶„ì„ê°€ë“¤ê³¼ ë‹¤ë¥¸ ìƒˆë¡œìš´ ì „ë¬¸ ë¶„ì•¼/ê´€ì 
        3. ìœ„ì— ë‚˜ì—´ëœ ê²€ìƒ‰ ë„êµ¬ë“¤ì„ ì ì ˆíˆ í™œìš©í•  ìˆ˜ ìˆëŠ” ì „ë¬¸ì„±
        4. ì‹¤ë¬´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ ê°€ëŠ¥
        
        ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
        {{
            "name": "ë¶„ì„ê°€ ì´ë¦„",
            "role": "ì—­í• ",
            "affiliation": "ì†Œì† ê¸°ê´€",
            "description": "í”¼ë“œë°±ì„ ë°˜ì˜í•œ ì „ë¬¸ì„±ê³¼ ì–´ë–¤ ê²€ìƒ‰ ë„êµ¬ë“¤ì„ ì£¼ë¡œ í™œìš©í• ì§€ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì„¤ëª… (ì˜ˆ: 'ë‰´ìŠ¤ì™€ ì›¹ ê²€ìƒ‰ì„ í™œìš©í•œ ì‹œì¥ ë™í–¥ ë¶„ì„')"
        }}
        """
        
        team = RoundRobinGroupChat([analyst_generator], termination_condition=MaxMessageTermination(max_messages=2))
        result = await team.run(task=analyst_prompt)
        
        # ê²°ê³¼ íŒŒì‹±
        try:
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            response_text = result.messages[-1].content
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            json_str = response_text[start_idx:end_idx]
            
            data = json.loads(json_str)
            return Analyst(**data)
        except Exception as e:
            print(f"ì¶”ê°€ ë¶„ì„ê°€ íŒŒì‹± ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return Analyst(
                name="í”¼ë“œë°± ì „ë¬¸ê°€",
                role="í”¼ë“œë°± ë¶„ì„ ì „ë¬¸ê°€",
                affiliation="ì—°êµ¬ ê¸°ê´€",
                description=f"í”¼ë“œë°± '{feedback}'ì„ ë°˜ì˜í•œ ì „ë¬¸ì  ë¶„ì„ì„ ë‹´ë‹¹"
            )
    
    async def _run_research_with_additional_analyst(self, task: ResearchTask, additional_analyst: Analyst) -> ResearchResult:
        """ì¶”ê°€ ë¶„ì„ê°€ë¥¼ í¬í•¨í•˜ì—¬ ê¸°ì¡´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì¬ì‹¤í–‰í•©ë‹ˆë‹¤"""
        
        # Langfuse ì¶”ì  ì‹œì‘
        task_id = str(uuid.uuid4())
        
        with self.tracing_manager.trace_research(topic=task.topic, task_id=task_id) as trace:
            try:
                print(f"ğŸ”„ ì¶”ê°€ ë¶„ì„ê°€ì™€ í•¨ê»˜ ì—°êµ¬ ì¬ì‹¤í–‰: {task.topic}")
                if trace:
                    trace_url = self.tracing_manager.get_trace_url()
                    if trace_url:
                        print(f"ğŸ” Langfuse ì¶”ì  ì‹œì‘ - Trace URL: {trace_url}")
                
                # ê¸°ì¡´ ë¶„ì„ê°€ë“¤ê³¼ ì¶”ê°€ ë¶„ì„ê°€ í•¨ê»˜ ì‚¬ìš©
                # interactive ëª¨ë“œì—ì„œ current_analystsê°€ ì¡´ì¬í•  ê²½ìš°
                if hasattr(self, 'current_analysts') and self.current_analysts:
                    analysts = self.current_analysts + [additional_analyst]
                else:
                    # ê¸°ë³¸ ëª¨ë“œì´ê±°ë‚˜ current_analystsê°€ ì—†ì„ ê²½ìš°
                    analysts = [additional_analyst]
                
                # ì¶”ê°€ ë¶„ì„ê°€ ìƒì„± ì´ë²¤íŠ¸ ë¡œê¹…
                self.tracing_manager.log_event(
                    "additional_analyst_created",
                    {
                        "analyst_name": additional_analyst.name,
                        "analyst_role": additional_analyst.role
                    }
                )
                
                # ì¸í„°ë·° ì§„í–‰
                print("ğŸ¤ ì¶”ê°€ ë¶„ì„ê°€ì™€ ì¸í„°ë·° ì§„í–‰ ì¤‘...")
                interviews = await self._conduct_interviews(analysts, task)
                print(f"âœ… {len(interviews)}ê°œì˜ ì¸í„°ë·° ì™„ë£Œ")
                
                # ì¸í„°ë·° ì™„ë£Œ ì´ë²¤íŠ¸ ë¡œê¹…
                self.tracing_manager.log_event(
                    "additional_interviews_completed",
                    {"count": len(interviews)}
                )
                
                # ë³´ê³ ì„œ ì‘ì„±
                print("ğŸ“ ì¶”ê°€ ì¸í„°ë·°ë¥¼ ë°˜ì˜í•œ ë³´ê³ ì„œ ì‘ì„± ì¤‘...")
                report_parts = await self._write_report(task.topic, interviews)
                print("âœ… ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œ")
                
                # ìµœì¢… ê²°ê³¼ ì¡°í•©
                final_report = self._assemble_final_report(report_parts)
                
                # ë³´ê³ ì„œ ìƒì„± ë¡œê¹…
                self.tracing_manager.log_generation(
                    "additional_final_report",
                    input_data={"topic": task.topic, "additional_analyst": additional_analyst.name},
                    output_data={"length": len(final_report), "word_count": len(final_report.split())}
                )
                
                result = ResearchResult(
                    topic=task.topic,
                    analysts=analysts,
                    interviews=interviews,
                    introduction=report_parts["introduction"],
                    main_content=report_parts["main_content"],
                    conclusion=report_parts["conclusion"],
                    final_report=final_report
                )
                
                # ì„±ê³µ ì´ë²¤íŠ¸ ë¡œê¹…
                self.tracing_manager.log_event(
                    "additional_research_completed",
                    {
                        "additional_analyst": additional_analyst.name,
                        "interview_count": len(interviews),
                        "report_length": len(final_report),
                        "word_count": len(final_report.split())
                    }
                )
                
                return result
            
            except Exception as e:
                print(f"âŒ ì¶”ê°€ ì—°êµ¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                
                # ì—ëŸ¬ ì´ë²¤íŠ¸ ë¡œê¹…
                self.tracing_manager.log_event(
                    "additional_research_error",
                    {"error": str(e), "error_type": type(e).__name__},
                    level="ERROR"
                )
                
                raise
    
    async def _conduct_interviews(self, analysts: List[Analyst], task: ResearchTask) -> List[InterviewResult]:
        """ë¶„ì„ê°€ë“¤ê³¼ ì „ë¬¸ê°€ ê°„ì˜ ì¸í„°ë·°ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤"""
        
        interviews = []
        
        if task.parallel_interviews:
            # ë³‘ë ¬ ì¸í„°ë·°
            interview_tasks = [
                self._conduct_single_interview(analyst, task.max_interview_turns)
                for analyst in analysts
            ]
            interview_results = await asyncio.gather(*interview_tasks)
            interviews.extend(interview_results)
        else:
            # ìˆœì°¨ ì¸í„°ë·°
            for analyst in analysts:
                interview_result = await self._conduct_single_interview(analyst, task.max_interview_turns)
                interviews.append(interview_result)
        
        return interviews
    
    async def _conduct_feedback_aware_interviews(self, analysts: List[Analyst], task: ResearchTask, feedback: str) -> List[InterviewResult]:
        """í”¼ë“œë°± ì»¨í…ìŠ¤íŠ¸ê°€ ê°•í™”ëœ ì¸í„°ë·°ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤"""
        
        interviews = []
        
        if task.parallel_interviews:
            # ë³‘ë ¬ ì¸í„°ë·° (í”¼ë“œë°± ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
            interview_tasks = [
                self._conduct_single_feedback_aware_interview(analyst, task.max_interview_turns, feedback)
                for analyst in analysts
            ]
            interview_results = await asyncio.gather(*interview_tasks)
            interviews.extend(interview_results)
        else:
            # ìˆœì°¨ ì¸í„°ë·° (í”¼ë“œë°± ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
            for analyst in analysts:
                interview_result = await self._conduct_single_feedback_aware_interview(analyst, task.max_interview_turns, feedback)
                interviews.append(interview_result)
        
        return interviews
    
    async def _conduct_single_feedback_aware_interview(self, analyst: Analyst, max_turns: int, feedback: str) -> InterviewResult:
        """í”¼ë“œë°± ì»¨í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ë‹¨ì¼ ì¸í„°ë·°ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤"""
        
        # í”¼ë“œë°± ì»¨í…ìŠ¤íŠ¸ê°€ ê°•í™”ëœ ì¸í„°ë·°ì–´ ìƒì„±
        interviewer = create_feedback_aware_interviewer(analyst, feedback, self.interviewer_model_client)
        expert = create_expert_agent(self.expert_model_client)
        section_writer = create_section_writer_agent(analyst, self.writer_model_client)
        
        # í”¼ë“œë°± ì¤‘ì‹¬ ì¸í„°ë·° ì§„í–‰
        termination = TextMentionTermination("ì •ë§ ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!") | MaxMessageTermination(max_messages=max_turns * 2 + 2)
        
        interview_team = RoundRobinGroupChat(
            [interviewer, expert],
            termination_condition=termination
        )
        
        # í”¼ë“œë°±ì´ ê°•ì¡°ëœ ì¸í„°ë·° í”„ë¡¬í”„íŠ¸
        interview_prompt = f"""
        {analyst.persona}ì˜ ê´€ì ì—ì„œ ì „ë¬¸ê°€ì™€ ì¸í„°ë·°ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”.
        
        **ì¤‘ìš” - ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜**: ë‹¤ìŒ ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ë“œì‹œ ê³ ë ¤í•˜ì—¬ ì§ˆë¬¸í•˜ì„¸ìš”:
        "{feedback}"
        
        ì´ í”¼ë“œë°±ì´ ìš”êµ¬í•˜ëŠ” ê´€ì , ì •ë³´, ê·¸ë¦¬ê³  ë¶„ì„ ë°©í–¥ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì¸í„°ë·°ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”.
        í”¼ë“œë°±ì—ì„œ ì–¸ê¸‰ëœ íŠ¹ì • ì˜ì—­ì´ë‚˜ ê´€ì ì— ëŒ€í•´ ê¹Šì´ ìˆê²Œ íƒêµ¬í•˜ì„¸ìš”.
        """
        
        interview_result = await interview_team.run(task=interview_prompt)
        
        # ì¸í„°ë·° ë‚´ìš© ì¶”ì¶œ (contentê°€ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        interview_content = "\n".join([
            msg.content if isinstance(msg.content, str) else str(msg.content) 
            for msg in interview_result.messages
        ])
        
        # í”¼ë“œë°± ì¤‘ì‹¬ ì¸í„°ë·° ì´ë²¤íŠ¸ ë¡œê¹…
        self.tracing_manager.log_event(
            "feedback_aware_interview_completed",
            {
                "interviewer": analyst.name,
                "analyst_role": analyst.role,
                "feedback": feedback[:100] + "..." if len(feedback) > 100 else feedback,
                "message_count": len(interview_result.messages),
                "content_length": len(interview_content)
            }
        )
        
        # í”¼ë“œë°±ì´ ë°˜ì˜ëœ ì„¹ì…˜ ì‘ì„±
        section_team = RoundRobinGroupChat(
            [section_writer],
            termination_condition=MaxMessageTermination(max_messages=2)
        )
        
        section_prompt = f"""
        ë‹¤ìŒ ì¸í„°ë·° ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œ ì„¹ì…˜ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
        
        **ì‚¬ìš©ì í”¼ë“œë°±**: {feedback}
        **ì¤‘ìš”**: ìœ„ í”¼ë“œë°±ì„ ì„¹ì…˜ ì‘ì„±ì— ì ê·¹ ë°˜ì˜í•˜ì—¬, ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê´€ì ê³¼ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.
        
        **ì¸í„°ë·° ë‚´ìš©**:
        {interview_content}
        """
        
        section_result = await section_team.run(task=section_prompt)
        section_content = section_result.messages[-1].content
        
        return InterviewResult(
            analyst=analyst,
            interview_content=interview_content,
            section_content=section_content
        )
    
    async def _conduct_single_interview(self, analyst: Analyst, max_turns: int) -> InterviewResult:
        """ë‹¨ì¼ ì¸í„°ë·°ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤"""
        
        interviewer = create_interviewer_agent(analyst, self.interviewer_model_client)
        expert = create_expert_agent(self.expert_model_client)
        section_writer = create_section_writer_agent(analyst, self.writer_model_client)
        
        # ì¸í„°ë·° ì§„í–‰
        termination = TextMentionTermination("ì •ë§ ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!") | MaxMessageTermination(max_messages=max_turns * 2 + 2)
        
        interview_team = RoundRobinGroupChat(
            [interviewer, expert],
            termination_condition=termination
        )
        
        interview_result = await interview_team.run(
            task=f"{analyst.persona}ì˜ ê´€ì ì—ì„œ ì „ë¬¸ê°€ì™€ ì¸í„°ë·°ë¥¼ ì§„í–‰í•´ì£¼ì„¸ìš”."
        )
        
        # ì¸í„°ë·° ë‚´ìš© ì¶”ì¶œ (contentê°€ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        interview_content = "\n".join([
            msg.content if isinstance(msg.content, str) else str(msg.content) 
            for msg in interview_result.messages
        ])
        
        # ì¸í„°ë·° ì´ë²¤íŠ¸ ë¡œê¹…
        self.tracing_manager.log_event(
            "interview_completed",
            {
                "interviewer": analyst.name,
                "analyst_role": analyst.role,
                "message_count": len(interview_result.messages),
                "content_length": len(interview_content)
            }
        )
        
        # ì„¹ì…˜ ì‘ì„±
        section_team = RoundRobinGroupChat(
            [section_writer],
            termination_condition=MaxMessageTermination(max_messages=2)
        )
        
        section_result = await section_team.run(
            task=f"ë‹¤ìŒ ì¸í„°ë·° ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œ ì„¹ì…˜ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:\n\n{interview_content}"
        )
        
        section_content = section_result.messages[-1].content
        
        return InterviewResult(
            analyst=analyst,
            interview_content=interview_content,
            section_content=section_content
        )
    
    async def _write_report(self, topic: str, interviews: List[InterviewResult]) -> Dict[str, str]:
        """ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤"""
        
        # ëª¨ë“  ì„¹ì…˜ ë‚´ìš© ìˆ˜ì§‘
        all_sections = "\n\n---\n\n".join([
            interview.section_content for interview in interviews
        ])
        
        # ë³´ê³ ì„œ ì‘ì„±ìë“¤ ìƒì„± (ê³ ì„±ëŠ¥ ëª¨ë¸ ì‚¬ìš©)
        report_writer = create_report_writer_agent(self.writer_model_client)
        intro_writer = create_intro_writer_agent(self.writer_model_client)
        conclusion_writer = create_conclusion_writer_agent(self.writer_model_client)
        
        # ë³‘ë ¬ë¡œ ê° ë¶€ë¶„ ì‘ì„±
        tasks = [
            self._write_main_content(report_writer, topic, all_sections),
            self._write_introduction(intro_writer, all_sections),
            self._write_conclusion(conclusion_writer, all_sections)
        ]
        
        main_content, introduction, conclusion = await asyncio.gather(*tasks)
        
        return {
            "main_content": main_content,
            "introduction": introduction,
            "conclusion": conclusion
        }
    
    async def _write_feedback_aware_report(self, topic: str, interviews: List[InterviewResult], feedback: str) -> Dict[str, str]:
        """í”¼ë“œë°± ì»¨í…ìŠ¤íŠ¸ê°€ ê°•í™”ëœ ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤"""
        
        # ëª¨ë“  ì„¹ì…˜ ë‚´ìš© ìˆ˜ì§‘
        all_sections = "\n\n---\n\n".join([
            interview.section_content for interview in interviews
        ])
        
        # í”¼ë“œë°± ì»¨í…ìŠ¤íŠ¸ê°€ ê°•í™”ëœ ë³´ê³ ì„œ ì‘ì„±ìë“¤ ìƒì„±
        report_writer = create_feedback_aware_report_writer(feedback, self.writer_model_client)
        intro_writer = create_feedback_aware_intro_writer(feedback, self.writer_model_client)
        conclusion_writer = create_feedback_aware_conclusion_writer(feedback, self.writer_model_client)
        
        # ë³‘ë ¬ë¡œ ê° ë¶€ë¶„ ì‘ì„± (í”¼ë“œë°± ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
        tasks = [
            self._write_main_content(report_writer, topic, all_sections),
            self._write_introduction(intro_writer, all_sections),
            self._write_conclusion(conclusion_writer, all_sections)
        ]
        
        main_content, introduction, conclusion = await asyncio.gather(*tasks)
        
        return {
            "main_content": main_content,
            "introduction": introduction,
            "conclusion": conclusion
        }
    
    async def _write_main_content(self, writer_agent, topic: str, sections: str) -> str:
        """ë©”ì¸ ì½˜í…ì¸ ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤"""
        
        team = RoundRobinGroupChat(
            [writer_agent],
            termination_condition=MaxMessageTermination(max_messages=2)
        )
        
        result = await team.run(
            task=f"ì£¼ì œ '{topic}'ì— ëŒ€í•œ ë‹¤ìŒ ì¸í„°ë·° ì„¹ì…˜ë“¤ì„ ì¢…í•©í•˜ì—¬ ë…ì°½ì ì´ê³  í¬ê´„ì ì¸ ì—°êµ¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ê° ì„¹ì…˜ì˜ ë‚´ìš©ì„ ë‹¨ìˆœ ë‚˜ì—´í•˜ì§€ ë§ê³  ìƒˆë¡œìš´ ê´€ì ìœ¼ë¡œ ì¢…í•©í•˜ì—¬ ì™„ì „íˆ ìƒˆë¡œìš´ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”:\n\n{sections}"
        )
        
        return result.messages[-1].content
    
    async def _write_introduction(self, intro_agent, sections: str) -> str:
        """ì„œë¡ ì„ ì‘ì„±í•©ë‹ˆë‹¤"""
        
        team = RoundRobinGroupChat(
            [intro_agent],
            termination_condition=MaxMessageTermination(max_messages=2)
        )
        
        result = await team.run(
            task=f"ë‹¤ìŒ ì¸í„°ë·° ì„¹ì…˜ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë…ì°½ì ì´ê³  ë§¤ë ¥ì ì¸ ì„œë¡ ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. ì„¹ì…˜ ë‚´ìš©ì„ ë‹¨ìˆœ ìš”ì•½í•˜ì§€ ë§ê³  ë…ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ê´€ì ì˜ ì„œë¡ ì„ ì‘ì„±í•˜ì„¸ìš”:\n\n{sections}"
        )
        
        return result.messages[-1].content
    
    async def _write_conclusion(self, conclusion_agent, sections: str) -> str:
        """ê²°ë¡ ì„ ì‘ì„±í•©ë‹ˆë‹¤"""
        
        team = RoundRobinGroupChat(
            [conclusion_agent],
            termination_condition=MaxMessageTermination(max_messages=2)
        )
        
        result = await team.run(
            task=f"ë‹¤ìŒ ì¸í„°ë·° ì„¹ì…˜ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë…ì°½ì ì´ê³  ê°•ë ¥í•œ ê²°ë¡ ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. ì„¹ì…˜ ë‚´ìš©ì„ ë‹¨ìˆœ ìš”ì•½í•˜ì§€ ë§ê³  ìƒˆë¡œìš´ ì¸ì‚¬ì´íŠ¸ì™€ ë¯¸ë˜ ì „ë§ì„ ì œì‹œí•˜ëŠ” ë…ì°½ì ì¸ ê²°ë¡ ì„ ì‘ì„±í•˜ì„¸ìš”:\n\n{sections}"
        )
        
        return result.messages[-1].content
    
    def _assemble_final_report(self, parts: Dict[str, str]) -> str:
        """ìµœì¢… ë³´ê³ ì„œë¥¼ ì¡°í•©í•©ë‹ˆë‹¤"""
        
        main_content = parts["main_content"]
        
        # ë©”ì¸ ì½˜í…ì¸ ê°€ ì´ë¯¸ ì™„ì „í•œ ë³´ê³ ì„œì¸ì§€ í™•ì¸
        if (("# " in main_content or "## ì„œë¡ " in main_content) and 
            ("ê²°ë¡ " in main_content.lower() or "## ê²°ë¡ " in main_content)):
            # ì´ë¯¸ ì™„ì „í•œ ë³´ê³ ì„œì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return main_content.strip()
        
        # ë©”ì¸ ì½˜í…ì¸ ì—ì„œ "## Insights" ì œëª© ì œê±°
        if main_content.startswith("## Insights"):
            main_content = main_content.replace("## Insights", "", 1).strip()
        
        # ì°¸ê³ ë¬¸í—Œ/ì†ŒìŠ¤ ì„¹ì…˜ ë¶„ë¦¬
        references = None
        sources = None
        
        # "## ì°¸ê³ ë¬¸í—Œ" ë˜ëŠ” "## References" ì°¾ê¸°
        if "## ì°¸ê³ ë¬¸í—Œ" in main_content:
            try:
                main_content, references = main_content.split("\n## ì°¸ê³ ë¬¸í—Œ\n", 1)
            except:
                references = None
        elif "## References" in main_content:
            try:
                main_content, references = main_content.split("\n## References\n", 1)
            except:
                references = None
        
        # "## Sources" ì°¾ê¸°
        if "## Sources" in main_content:
            try:
                main_content, sources = main_content.split("\n## Sources\n", 1)
            except:
                sources = None
        
        # ê°œë³„ ì„¹ì…˜ë“¤ì„ ì¡°í•©í•˜ì—¬ ì™„ì „í•œ ë³´ê³ ì„œ ìƒì„±
        final_report = (
            parts["introduction"] + 
            "\n\n---\n\n## ì£¼ìš” ë‚´ìš©\n\n" + 
            main_content + 
            "\n\n---\n\n" + 
            parts["conclusion"]
        )
        
        # ì°¸ê³ ë¬¸í—Œ ì„¹ì…˜ ì¶”ê°€
        if references:
            final_report += "\n\n## ì°¸ê³ ë¬¸í—Œ\n" + references
        elif sources:
            final_report += "\n\n## Sources\n" + sources
        
        return final_report
    
    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        await self.model_client.close()
        
        # Langfuse ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        if self.tracing_manager.enabled:
            self.tracing_manager.close()


def create_storm_workflow(config: StormConfig, interactive_mode: bool = False) -> StormWorkflow:
    """STORM ì›Œí¬í”Œë¡œìš°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
    
    Args:
        config: STORM ì„¤ì •
        interactive_mode: ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ í™œì„±í™” ì—¬ë¶€
        
    Returns:
        StormWorkflow ì¸ìŠ¤í„´ìŠ¤
    """
    return StormWorkflow(config, interactive_mode)
